{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12da5e9-44de-4459-86c8-27cefdad4950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:14:23.029461Z",
     "iopub.status.busy": "2024-10-20T12:14:23.029121Z",
     "iopub.status.idle": "2024-10-20T12:14:56.448746Z",
     "shell.execute_reply": "2024-10-20T12:14:56.448056Z",
     "shell.execute_reply.started": "2024-10-20T12:14:23.029424Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63a9cedc0f24de386dbc7a352607f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1729426168720_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-103.us-east-2.compute.internal:20888/proxy/application_1729426168720_0001/\" class=\"emr-proxy-link j-1RKSZLNB3EVAO application_1729426168720_0001\" emr-resource=\"j-1RKSZLNB3EVAO\n",
       "\" application-id=\"application_1729426168720_0001\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-17-122.us-east-2.compute.internal:8042/node/containerlogs/container_1729426168720_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of spark.kryoserializer.buffer.max is: 2047m\n",
      "Current spark.executor.memory: 80G\n",
      "spark.network.timeout: 1600s\n",
      "spark.driver.maxResultSize: Not Set\n",
      "spark.executor.heartbeatInterval: Not Set"
     ]
    }
   ],
   "source": [
    "#Load Libraries and initialize session\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Initialize Spark session with updated configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud Detection Feature Engineering\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2047m\") \\\n",
    "    .config(\"spark.executor.memory\", \"80G\") \\\n",
    "    .config(\"spark.shuffle.compress\", \"true\") \\\n",
    "    .config(\"spark.shuffle.spill.compress\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Retrieve the value of spark.config\n",
    "network_timeout = spark.conf.get(\"spark.network.timeout\", \"Not Set\")\n",
    "max_result_size = spark.conf.get(\"spark.driver.maxResultSize\", \"Not Set\")\n",
    "heartbeat_interval = spark.conf.get(\"spark.executor.heartbeatInterval\", \"Not Set\")\n",
    "buffer_max = spark.conf.get(\"spark.kryoserializer.buffer.max\")\n",
    "print(f\"The value of spark.kryoserializer.buffer.max is: {buffer_max}\")\n",
    "executor_memory = spark.conf.get(\"spark.executor.memory\")\n",
    "print(f\"Current spark.executor.memory: {executor_memory}\")\n",
    "print(f\"spark.network.timeout: {network_timeout}\")\n",
    "print(f\"spark.driver.maxResultSize: {max_result_size}\")\n",
    "print(f\"spark.executor.heartbeatInterval: {heartbeat_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c4f4c3-94b8-47ac-b960-3b01e9c0ff8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:14:56.450018Z",
     "iopub.status.busy": "2024-10-20T12:14:56.449802Z",
     "iopub.status.idle": "2024-10-20T12:15:05.780397Z",
     "shell.execute_reply": "2024-10-20T12:15:05.779648Z",
     "shell.execute_reply.started": "2024-10-20T12:14:56.449969Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0472a922bcd412fb0ce453e0173f5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Schema:\n",
      "root\n",
      " |-- CUSTOMER_ID: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- billing_street: string (nullable = true)\n",
      " |-- billing_city: string (nullable = true)\n",
      " |-- billing_state: string (nullable = true)\n",
      " |-- billing_zip: string (nullable = true)\n",
      " |-- customer_job: string (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- x_customer_id: double (nullable = true)\n",
      " |-- y_customer_id: double (nullable = true)\n",
      " |-- mean_amount: double (nullable = true)\n",
      " |-- std_amount: double (nullable = true)\n",
      " |-- mean_nb_tx_per_day: double (nullable = true)\n",
      " |-- std_dev_nb_tx_per_day: double (nullable = true)\n",
      " |-- available_terminals: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Terminals Schema:\n",
      "root\n",
      " |-- TERMINAL_ID: string (nullable = true)\n",
      " |-- x_terminal_id: double (nullable = true)\n",
      " |-- y_terminal_id: double (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      "\n",
      "Transactions Schema:\n",
      "root\n",
      " |-- TX_DATETIME: string (nullable = true)\n",
      " |-- CUSTOMER_ID: string (nullable = true)\n",
      " |-- TERMINAL_ID: string (nullable = true)\n",
      " |-- TX_AMOUNT: double (nullable = true)\n",
      " |-- TX_TIME_SECONDS: long (nullable = true)\n",
      " |-- TX_TIME_DAYS: integer (nullable = true)\n",
      " |-- TX_FRAUD: integer (nullable = true)\n",
      " |-- month: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Load datasets and infer schema\n",
    "customers_path = \"s3://nvidia-aws-fraud-detection-demo-training-data/customers_parquet/\"\n",
    "terminals_path = \"s3://nvidia-aws-fraud-detection-demo-training-data/terminals_parquet/\"\n",
    "transactions_path = \"s3://nvidia-aws-fraud-detection-demo-training-data/transactions_parquet/\"\n",
    "\n",
    "customers_df = spark.read.parquet(customers_path).repartition(300)\n",
    "terminals_df = spark.read.parquet(terminals_path)\n",
    "transactions_df = spark.read.parquet(transactions_path).repartition(1000)\n",
    "_\n",
    "# Show schema of each dataset to understand their structure\n",
    "print(\"Customers Schema:\")\n",
    "customers_df.printSchema()\n",
    "\n",
    "print(\"Terminals Schema:\")\n",
    "terminals_df.printSchema()\n",
    "\n",
    "print(\"Transactions Schema:\")\n",
    "transactions_df.printSchema()\n",
    "\n",
    "# Count the rows in each dataset to understand the size\n",
    "#print(f\"Number of rows in customers: {customers_df.count()}\")\n",
    "#print(f\"Number of rows in terminals: {terminals_df.count()}\")\n",
    "#print(f\"Number of rows in transactions: {transactions_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5daaefd-fa96-4c24-8a70-03210dd49585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:15:05.781534Z",
     "iopub.status.busy": "2024-10-20T12:15:05.781359Z",
     "iopub.status.idle": "2024-10-20T12:15:06.039330Z",
     "shell.execute_reply": "2024-10-20T12:15:06.038692Z",
     "shell.execute_reply.started": "2024-10-20T12:15:05.781510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810dc6eee9cf46d480bbd3da5f2b410f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Broadcast smaller tables for efficient joins\n",
    "terminals_df = broadcast(terminals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d20ad4-5145-4b58-8747-d3ff6e6868f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:15:06.040398Z",
     "iopub.status.busy": "2024-10-20T12:15:06.040226Z",
     "iopub.status.idle": "2024-10-20T12:15:06.300418Z",
     "shell.execute_reply": "2024-10-20T12:15:06.299813Z",
     "shell.execute_reply.started": "2024-10-20T12:15:06.040376Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c338511da9784351be85624d3f1c2394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the TX_DATETIME column to timestamp\n",
    "transactions_df = transactions_df.withColumn(\n",
    "    \"TX_DATETIME\",\n",
    "    F.col(\"TX_DATETIME\").cast(\"timestamp\"))\n",
    "\n",
    "# Split TX_DATETIME into yyyy, mm, and dd columns\n",
    "transactions_df = transactions_df.withColumn(\"yyyy\", year(F.col(\"TX_DATETIME\"))) \\\n",
    "                                 .withColumn(\"mm\", month(F.col(\"TX_DATETIME\"))) \\\n",
    "                                 .withColumn(\"dd\", dayofmonth(F.col(\"TX_DATETIME\")))\n",
    "\n",
    "# Define time windows in seconds for feature extraction\n",
    "time_windows = {\n",
    "    \"15min\": 15 * 60,\n",
    "    \"30min\": 30 * 60,\n",
    "    \"60min\": 60 * 60,\n",
    "    \"1day\": 24 * 60 * 60,\n",
    "    \"7day\": 7 * 24 * 60 * 60,\n",
    "    \"15day\": 15 * 24 * 60 * 60,\n",
    "    \"30day\": 30 * 24 * 60 * 60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d130e0-70b3-4892-921c-948862b990cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:15:06.302015Z",
     "iopub.status.busy": "2024-10-20T12:15:06.301848Z",
     "iopub.status.idle": "2024-10-20T12:23:13.490975Z",
     "shell.execute_reply": "2024-10-20T12:23:13.490302Z",
     "shell.execute_reply.started": "2024-10-20T12:15:06.301993Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7d4191ef0343d2a33efda3b0f743ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to add window features efficiently\n",
    "def add_window_features(transactions_df, time_windows, entity_id_col, prefix):\n",
    "    for window_name, window_duration in time_windows.items():\n",
    "        window_spec = Window.partitionBy(entity_id_col).orderBy(\n",
    "            F.col(\"TX_DATETIME\").cast(\"long\")).rangeBetween(\n",
    "                -window_duration, 0)\n",
    "\n",
    "        # Number of transactions in the time window\n",
    "        transactions_df = transactions_df.withColumn(\n",
    "            f\"{prefix}_nb_txns_{window_name}_window\",\n",
    "            F.count(\"*\").over(window_spec))\n",
    "\n",
    "        # Average transaction amount in the time window\n",
    "        transactions_df = transactions_df.withColumn(\n",
    "            f\"{prefix}_avg_amt_{window_name}_window\",\n",
    "            F.avg(\"TX_AMOUNT\").over(window_spec))\n",
    "\n",
    "    return transactions_df\n",
    "\n",
    "\n",
    "# Add customer-related features\n",
    "transactions_df = add_window_features(transactions_df, time_windows,\n",
    "                                      \"CUSTOMER_ID\", \"customer_id\")\n",
    "\n",
    "# Add terminal-related features\n",
    "transactions_df = add_window_features(transactions_df, time_windows,\n",
    "                                      \"TERMINAL_ID\", \"terminal_id\")\n",
    "\n",
    "# Ordinal Encoding using StringIndexer for CUSTOMER_ID and TERMINAL_ID\n",
    "customer_indexer = StringIndexer(inputCol=\"CUSTOMER_ID\",\n",
    "                                 outputCol=\"CUSTOMER_ID_index\",\n",
    "                                 handleInvalid=\"keep\").fit(transactions_df)\n",
    "transactions_df = customer_indexer.transform(transactions_df)\n",
    "\n",
    "# Apply the same StringIndexer to customers_df to create the CUSTOMER_ID_index column\n",
    "customers_df = customer_indexer.transform(customers_df)\n",
    "\n",
    "# Ordinal encoding for other columns in customers_df\n",
    "columns_to_encode_customers = ['customer_name', 'customer_email', 'phone']\n",
    "for column in columns_to_encode_customers:\n",
    "    if column in customers_df.columns:\n",
    "        indexer = StringIndexer(inputCol=column,\n",
    "                                outputCol=f\"{column}_index\",\n",
    "                                handleInvalid=\"keep\").fit(customers_df)\n",
    "        customers_df = indexer.transform(customers_df)\n",
    "\n",
    "# Ordinal encoding for TERMINAL_ID in transactions_df\n",
    "terminal_indexer = StringIndexer(inputCol=\"TERMINAL_ID\",\n",
    "                                 outputCol=\"TERMINAL_ID_index\",\n",
    "                                 handleInvalid=\"keep\").fit(transactions_df)\n",
    "transactions_df = terminal_indexer.transform(transactions_df)\n",
    "\n",
    "# Apply the same StringIndexer to terminals_df to create the TERMINAL_ID_index column\n",
    "terminals_df = terminal_indexer.transform(terminals_df)\n",
    "\n",
    "# Ordinal encoding for merchant in both transactions_df and terminals_df\n",
    "if 'merchant' in transactions_df.columns:\n",
    "    merchant_indexer = StringIndexer(inputCol='merchant',\n",
    "                                     outputCol='merchant_index',\n",
    "                                     handleInvalid=\"keep\").fit(transactions_df)\n",
    "    transactions_df = merchant_indexer.transform(transactions_df)\n",
    "\n",
    "if 'merchant' in terminals_df.columns:\n",
    "    merchant_indexer_terminals = StringIndexer(\n",
    "        inputCol='merchant', outputCol='merchant_index',\n",
    "        handleInvalid=\"keep\").fit(terminals_df)\n",
    "    terminals_df = merchant_indexer_terminals.transform(terminals_df)\n",
    "\n",
    "# Apply StringIndexer to additional categorical columns in transactions_df\n",
    "columns_to_encode_transactions = ['merchant']  # Already handled 'merchant'\n",
    "for column in columns_to_encode_transactions:\n",
    "    if column in transactions_df.columns:\n",
    "        indexer = StringIndexer(inputCol=column,\n",
    "                                outputCol=f\"{column}_index\",\n",
    "                                handleInvalid=\"keep\").fit(transactions_df)\n",
    "        transactions_df = indexer.transform(transactions_df)\n",
    "        transactions_df = transactions_df.drop(column)\n",
    "\n",
    "# One-hot encoding for TX_FRAUD\n",
    "transactions_df = transactions_df.withColumn(\n",
    "    \"TX_FRAUD_0\", (F.col(\"TX_FRAUD\") == 0).cast(\"int\"))\n",
    "transactions_df = transactions_df.withColumn(\n",
    "    \"TX_FRAUD_1\", (F.col(\"TX_FRAUD\") == 1).cast(\"int\"))\n",
    "\n",
    "# Drop TX_FRAUD and TX_DATETIME column after encoding\n",
    "transactions_df = transactions_df.drop(\"TX_FRAUD\")\n",
    "\n",
    "transactions_df = transactions_df.drop(\"TX_DATETIME\")\n",
    "\n",
    "# Apply StringIndexer for billing_city and billing_state in customers_df\n",
    "billing_city_indexer = StringIndexer(inputCol=\"billing_city\", outputCol=\"billing_city_index\").fit(customers_df)\n",
    "customers_df = billing_city_indexer.transform(customers_df)\n",
    "\n",
    "billing_state_indexer = StringIndexer(inputCol=\"billing_state\", outputCol=\"billing_state_index\").fit(customers_df)\n",
    "customers_df = billing_state_indexer.transform(customers_df)\n",
    "\n",
    "# Drop the original columns after encoding\n",
    "customers_df = customers_df.drop(\"billing_city\", \"billing_state\")\n",
    "\n",
    "# Join the enriched transactions data with customer and terminal details\n",
    "#intermediate_df = transactions_df.join(customers_df,\n",
    "#                                on=\"CUSTOMER_ID_index\",\n",
    "#                                how=\"right\").join(terminals_df,\n",
    "#                                                 on=\"TERMINAL_ID_index\",\n",
    "#                                                 how=\"right\")\n",
    "#print(f\"Total number of rows for right join: {intermediate_df.count()}\")\n",
    "\n",
    "final_df = transactions_df.join(customers_df,\n",
    "                                on=\"CUSTOMER_ID_index\",\n",
    "                                how=\"left\").join(terminals_df,\n",
    "                                                 on=\"TERMINAL_ID_index\",\n",
    "                                                 how=\"left\")\n",
    "#print(f\"Total number of rows for left join: {final_df.count()}\")\n",
    "\n",
    "\n",
    "# Select the final features and customer/terminal details\n",
    "final_columns = [\n",
    "    \"CUSTOMER_ID_index\",\n",
    "    \"customer_name_index\",\n",
    "    \"customer_email_index\",\n",
    "    \"phone_index\",\n",
    "    \"billing_zip\",\n",
    "    \"billing_city_index\",  # Ordinal encoded billing_city\n",
    "    \"billing_state_index\", # Ordinal encoded billing_state\n",
    "    \"x_customer_id\",  # Added column\n",
    "    \"y_customer_id\",  # Added column\n",
    "    \"TX_AMOUNT\",\n",
    "    \"TX_FRAUD_0\",  # One-hot encoded column\n",
    "    \"TX_FRAUD_1\",  # One-hot encoded column   \n",
    "    \"TERMINAL_ID_index\",\n",
    "    \"merchant_index\",  # Ensure 'merchant_index' is present\n",
    "    \"yyyy\",\n",
    "    \"mm\",\n",
    "    \"dd\",\n",
    "    # Customer-related features\n",
    "    \"customer_id_nb_txns_15min_window\",\n",
    "    \"customer_id_nb_txns_30min_window\",\n",
    "    \"customer_id_nb_txns_60min_window\",\n",
    "    \"customer_id_nb_txns_1day_window\",\n",
    "    \"customer_id_nb_txns_7day_window\",\n",
    "    \"customer_id_nb_txns_15day_window\",\n",
    "    \"customer_id_nb_txns_30day_window\",\n",
    "    \"customer_id_avg_amt_15min_window\",\n",
    "    \"customer_id_avg_amt_30min_window\",\n",
    "    \"customer_id_avg_amt_60min_window\",\n",
    "    \"customer_id_avg_amt_1day_window\",\n",
    "    \"customer_id_avg_amt_7day_window\",\n",
    "    \"customer_id_avg_amt_15day_window\",\n",
    "    \"customer_id_avg_amt_30day_window\",\n",
    "    # Terminal-related features\n",
    "    \"terminal_id_nb_txns_15min_window\",\n",
    "    \"terminal_id_nb_txns_30min_window\",\n",
    "    \"terminal_id_nb_txns_60min_window\",\n",
    "    \"terminal_id_nb_txns_1day_window\",\n",
    "    \"terminal_id_nb_txns_7day_window\",\n",
    "    \"terminal_id_nb_txns_15day_window\",\n",
    "    \"terminal_id_nb_txns_30day_window\",\n",
    "    \"terminal_id_avg_amt_15min_window\",\n",
    "    \"terminal_id_avg_amt_30min_window\",\n",
    "    \"terminal_id_avg_amt_60min_window\",\n",
    "    \"terminal_id_avg_amt_1day_window\",\n",
    "    \"terminal_id_avg_amt_7day_window\",\n",
    "    \"terminal_id_avg_amt_15day_window\",\n",
    "    \"terminal_id_avg_amt_30day_window\"\n",
    "]\n",
    "\n",
    "final_df = final_df.select(final_columns).repartition(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81f498-533b-4ca3-b55c-68e6f1c1521a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:23:13.492345Z",
     "iopub.status.busy": "2024-10-20T12:23:13.492176Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723c0f6be46248dfa213015cd339f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8462cf0f61f644e1aaf0f432d130cd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the result to S3 as Parquet\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128M\")\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"500M\")\n",
    "final_output_path = \"s3://nvidia-aws-fraud-detection-demo/output121/\"\n",
    "final_df.write.mode(\"overwrite\").parquet(final_output_path)\n",
    "\n",
    "print(f\"Data successfully written to {final_output_path}\")\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
